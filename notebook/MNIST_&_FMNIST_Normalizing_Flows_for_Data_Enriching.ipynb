{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_&_FMNIST_Normalizing_Flows_for_Data_Enriching.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFiD9xG3TAyW"
      },
      "source": [
        "# Latent Attacks with Normalizing Flows\n",
        "\n",
        "* We will use [FrEIA](https://github.com/VLL-HD/FrEIA) framework written in [PyTorch](https://pytorch.org/) to easily implement normalizing flows.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7omWuVgoSS6T"
      },
      "source": [
        "# install FrEIA framework\n",
        "!pip install git+https://github.com/VLL-HD/FrEIA.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBXpviKeWL9Q"
      },
      "source": [
        "# global imports\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "import FrEIA.framework as Ff\n",
        "import FrEIA.modules as Fm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE3srolPO4zl"
      },
      "source": [
        "DATASET = 'mnist' # 'fmnist'\n",
        "MODEL = 'lenet' # 'standard'\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejtg2iFMYRQD"
      },
      "source": [
        "## Models\n",
        "\n",
        "Let's start by defining our normalizing flows. Here is a normalizing flows directly taken from [FrEIA](https://github.com/VLL-HD/FrEIA) main page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL-P1C7PTtUD"
      },
      "source": [
        "def subnet_fc(c_in, c_out, c_hidden=512):\n",
        "    return nn.Sequential(nn.Linear(c_in, c_hidden), nn.ReLU(),\n",
        "                         nn.Linear(c_hidden, c_out))\n",
        "\n",
        "def subnet_conv(c_in, c_out, c_hidden=256):\n",
        "    return nn.Sequential(nn.Conv2d(c_in, c_hidden, 3, padding=1), nn.ReLU(),\n",
        "                         nn.Conv2d(c_hidden, c_out, 3, padding=1))\n",
        "\n",
        "def subnet_conv_1x1(c_in, c_out, c_hidden=256):\n",
        "    return nn.Sequential(nn.Conv2d(c_in, c_hidden, 1), nn.ReLU(),\n",
        "                         nn.Conv2d(c_hidden, c_out, 1))\n",
        "\n",
        "def build_flow(layers=12):\n",
        "    cond = Ff.ConditionNode(10, name='condition')\n",
        "    nodes = [Ff.InputNode(28*28, name='input')]\n",
        "\n",
        "    for k in range(layers):\n",
        "        nodes.append(Ff.Node(nodes[-1],\n",
        "                            Fm.GLOWCouplingBlock,\n",
        "                            {'subnet_constructor': subnet_fc, 'clamp':2.0},\n",
        "                            conditions=cond,\n",
        "                            name=F'coupling_{k}'))\n",
        "        nodes.append(Ff.Node(nodes[-1],\n",
        "                            Fm.PermuteRandom,\n",
        "                            {'seed':k},\n",
        "                            name=F'permute_{k}'))\n",
        "\n",
        "    nodes.append(Ff.OutputNode(nodes[-1], name='output'))\n",
        "    return Ff.ReversibleGraphNet(nodes + [cond])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xJ_fxIaXII8"
      },
      "source": [
        "Next, we will define simple convolution classfiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-mGJof1reH-"
      },
      "source": [
        "from scipy.stats import truncnorm\n",
        "\n",
        "def truncated_normal(size, threshold=1):\n",
        "    \"\"\"Samples values from truncated normal distribution centered at 0\n",
        "    Args:\n",
        "        size: shape or amount of samples\n",
        "        threshold: cut-off value for distribution\n",
        "    Returns:\n",
        "        numpy array of given size\n",
        "    \"\"\"\n",
        "    return truncnorm.rvs(-threshold, threshold, size=size)\n",
        "\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    \"\"\"LeNet-5 from `\"Gradient-Based Learning Applied To Document Recognition\"\n",
        "    <http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=2)\n",
        "        self._init_weights()\n",
        "\n",
        "    # ref: https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778\n",
        "    def _init_weights(self) -> None:\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                # truncated normal distribution with std 0.1 (truncate > 2 x std)\n",
        "                # https://www.tensorflow.org/api_docs/python/tf/random/truncated_normal\n",
        "                weights = truncated_normal(list(m.weight.shape), threshold=0.1 * 2)\n",
        "                weights = torch.from_numpy(weights)\n",
        "                m.weight.data.copy_(weights)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.avgpool(self.relu(self.conv1(x)))\n",
        "        x = self.avgpool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5QyNZXPM8wF"
      },
      "source": [
        " class Classifier(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Simple classifier.\n",
        "    \"\"\"\n",
        "\n",
        "    def add_layer(self, name, layer):\n",
        "        \"\"\"\n",
        "        Add a layer.\n",
        "        :param name:\n",
        "        :param layer:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        setattr(self, name, layer)\n",
        "        self.layers.append(name)\n",
        "    \n",
        "    def __init__(self, N_class=10, resolution=[1,28,28]):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.layers = []\n",
        "\n",
        "        layer = 0\n",
        "        channels = []\n",
        "        resolutions = []\n",
        "\n",
        "        # Determine parameters of network\n",
        "        activation = torch.nn.ReLU\n",
        "        gain = 1\n",
        "        if activation:\n",
        "            gain = torch.nn.init.calculate_gain('relu')\n",
        "\n",
        "        batch_normalization = True\n",
        "        dropout = False\n",
        "        start_channels = 16\n",
        "        kernel_size = 4\n",
        "        assert kernel_size%2 == 0\n",
        "\n",
        "        while True:\n",
        "            input_channels = resolution[0] if layer == 0 else channels[layer - 1]\n",
        "            output_channels = start_channels if layer == 0 else channels[layer - 1]*2\n",
        "\n",
        "            conv = torch.nn.Conv2d(input_channels, output_channels, kernel_size=kernel_size, stride=2, padding=kernel_size//2-1)\n",
        "            torch.nn.init.kaiming_normal_(conv.weight, gain)\n",
        "            torch.nn.init.constant_(conv.bias, 0)\n",
        "            self.add_layer('conv%d' % layer, conv)\n",
        "\n",
        "            if batch_normalization:\n",
        "                bn = torch.nn.BatchNorm2d(output_channels)\n",
        "                torch.nn.init.constant_(bn.weight, 1)\n",
        "                torch.nn.init.constant_(bn.bias, 0)\n",
        "                self.add_layer('bn%d' % layer, bn)\n",
        "\n",
        "            if activation:\n",
        "                relu = activation(True)\n",
        "                self.add_layer('act%d' % layer, relu)\n",
        "\n",
        "            channels.append(output_channels)\n",
        "            resolutions.append([\n",
        "                resolution[1] // 2 if layer == 0 else resolutions[layer - 1][0] // 2,\n",
        "                resolution[2] // 2 if layer == 0 else resolutions[layer - 1][1] // 2\n",
        "            ])\n",
        "            if resolutions[-1][0] // 2 < 2 or resolutions[-1][1] < 2:\n",
        "                break;\n",
        "\n",
        "            layer += 1\n",
        "\n",
        "        representation = int(resolutions[-1][0]*resolutions[-1][1]*channels[-1])\n",
        "        view = Lambda(lambda x: x.view(x.size(0), -1))\n",
        "        self.add_layer('view', view)\n",
        "\n",
        "        linear1 = torch.nn.Linear(representation, 10*N_class)\n",
        "        linear2 = torch.nn.Linear(10*N_class, N_class)\n",
        "\n",
        "        torch.nn.init.kaiming_normal_(linear1.weight, gain)\n",
        "        #torch.nn.init.normal_(linear1.weight, 0, 0.001)\n",
        "        torch.nn.init.constant_(linear1.bias, 0)\n",
        "        torch.nn.init.kaiming_normal_(linear2.weight, gain)\n",
        "        #torch.nn.init.normal_(linear2.weight, 0, 0.001)\n",
        "        torch.nn.init.constant_(linear2.bias, 0)\n",
        "\n",
        "        self.add_layer('representation', linear1)\n",
        "        if dropout:\n",
        "            drop = torch.nn.Dropout()\n",
        "            self.add_layer('drop%d' % layer, drop)\n",
        "        self.add_layer('logits', linear2) \n",
        " \n",
        "    def forward(self, image, return_features=False):\n",
        "        \"\"\"\n",
        "        Forward pass, takes an image and outputs the predictions.\n",
        "        :param image: input image\n",
        "        :type image: torch.autograd.Variable\n",
        "        :param return_representation: whether to also return representation layer\n",
        "        :type return_representation: bool\n",
        "        :return: logits\n",
        "        :rtype: torch.autograd.Variable\n",
        "        \"\"\"\n",
        "\n",
        "        features = []\n",
        "        output = image\n",
        "\n",
        "        for name in self.layers:\n",
        "            output = getattr(self, name)(output)\n",
        "            features.append(output)\n",
        "        if return_features:\n",
        "            return output, features\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Print network.\n",
        "        \"\"\"\n",
        "\n",
        "        string = ''\n",
        "        for name in self.layers:\n",
        "            string += '(' + name + ', ' + getattr(self, name).__class__.__name__ + ')\\n'\n",
        "            if type(getattr(self, name)).__class__.__name__ == 'Sequential':\n",
        "                for module in getattr(self, name).modules():\n",
        "                    string += '\\t(' + module.__class__.__name__ + ')'\n",
        "        return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn69MiVvXKvM"
      },
      "source": [
        "#define a custom layer for view operations\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "def build_conv(net: str = MODEL):\n",
        "    if net == 'lenet':\n",
        "        return LeNet()\n",
        "    elif net == 'standard':\n",
        "        return Classifier()\n",
        "    else:\n",
        "        raise ValueError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78DD4mRSYXw0"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDECh4s440jq"
      },
      "source": [
        "import collections\n",
        "from typing import Callable, List, Optional, Tuple\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
        "\n",
        "def split_dataset(dataset: Dataset, split: float, seed: int) -> Tuple[Subset, Subset]:\n",
        "    \"\"\"Splits dataset into a train / val set based on a split value and seed\n",
        "\n",
        "    Args:\n",
        "        dataset: dataset to split\n",
        "        split: The proportion of the dataset to include in the validation split,\n",
        "            must be between 0 and 1.\n",
        "        seed: Seed used to generate the split\n",
        "\n",
        "    Returns:\n",
        "        Subsets of the input dataset\n",
        "\n",
        "    \"\"\"\n",
        "    # Verify that the dataset is Sized\n",
        "    if not isinstance(dataset, collections.abc.Sized):\n",
        "        raise ValueError(\"Dataset is not Sized!\")\n",
        "\n",
        "    if not (0 <= split <= 1):\n",
        "        raise ValueError(f\"Split value must be between 0 and 1. Value: {split}\")\n",
        "\n",
        "    val_length = int(len(dataset) * split)\n",
        "    train_length = len(dataset) - val_length\n",
        "    splits = random_split(\n",
        "        dataset,\n",
        "        [train_length, val_length],\n",
        "        generator=torch.Generator().manual_seed(seed),\n",
        "    )\n",
        "    return splits\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkUf__pNWBG7"
      },
      "source": [
        "from typing import Tuple\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def prepare_dataset(\n",
        "    dataset: str = DATASET,\n",
        "    augmentation: bool = False,\n",
        "    split: float = 0,\n",
        "    seed: int = 9999,\n",
        "    batch_size = BATCH_SIZE) -> Tuple[DataLoader, DataLoader]:\n",
        "    train_augmentations = [transforms.ToTensor()]\n",
        "    if augmentation:\n",
        "        train_augmentations += [\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(0.15),\n",
        "            transforms.RandomCrop(28, padding=4)\n",
        "        ]\n",
        "\n",
        "    # download data and prepare loaders\n",
        "\n",
        "    if dataset == 'mnist':\n",
        "        train_set = datasets.MNIST(\n",
        "            'mnist/train',\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                train_augmentations\n",
        "            ))\n",
        "\n",
        "        test_set = datasets.MNIST(\n",
        "            'mnist/train',\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transforms.Compose([\n",
        "                transforms.ToTensor()\n",
        "            ]))\n",
        "    elif dataset == 'fmnist':\n",
        "        train_set = datasets.FashionMNIST(\n",
        "            'fmnist/train',\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                train_augmentations\n",
        "            ))\n",
        "\n",
        "        test_set = datasets.FashionMNIST(\n",
        "            'fmnist/train',\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transforms.Compose([\n",
        "                transforms.ToTensor()\n",
        "            ]))\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    if split > 0:\n",
        "        train_set, _ = split_dataset(\n",
        "            dataset=train_set, split=split, seed=seed,\n",
        "        )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False)\n",
        "    \n",
        "    return train_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EjfWU6yYckP"
      },
      "source": [
        "## Training\n",
        "\n",
        "We will train various models:\n",
        "\n",
        "1. Normalizing Flow for generation of images\n",
        "2. Convolutional Classifier on standard images\n",
        "3. Convolutional Classifier on Flow outputs\n",
        "4. Convolutional Classifier on Flow-perturbed images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n6jN8f9gyMN"
      },
      "source": [
        "### Generative Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNqZd66QOnZf"
      },
      "source": [
        "Let's train our conditional flow with MNIST/FashionMNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JLWkvFHeKi4"
      },
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "\n",
        "# training function for flow\n",
        "def train_flow(flow):\n",
        "    # define hyperparams\n",
        "    ### optimizer\n",
        "    lr = 1e-6\n",
        "    betas = (0.9, 0.999)\n",
        "    eps = 1e-8\n",
        "    weight_decay = 0\n",
        "\n",
        "    ### training\n",
        "    epochs = 100\n",
        "    noise = 0.1\n",
        "\n",
        "    # define optimizer\n",
        "    flow_params = list(filter(lambda p: p.requires_grad, flow.parameters()))\n",
        "    flow_optim = Adam(\n",
        "        flow_params,\n",
        "        lr=lr,\n",
        "        betas=betas,\n",
        "        eps=eps,\n",
        "        weight_decay=weight_decay)\n",
        "\n",
        "    # preprocess data for flow\n",
        "    def prepare_inputs(x, y):\n",
        "        # prepare shapes\n",
        "        x = x.view(-1, 1*28*28)\n",
        "        y = F.one_hot(y, num_classes=10)\n",
        "\n",
        "        # add to cuda\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        # add a small noise to inputs\n",
        "        x += noise * torch.cuda.FloatTensor(x.shape).normal_()\n",
        "        \n",
        "        # clamp if x is out of bounds\n",
        "        x = torch.clamp(x, 0., 1.)\n",
        "\n",
        "        # return as a tuple\n",
        "        return x, y\n",
        "\n",
        "    # calculate loss of flow model\n",
        "    def flow_loss(x, y):\n",
        "        # feed-forward\n",
        "        z, log_jac_det = flow(x, y)\n",
        "\n",
        "        # calculate prior (standard Gaussian) & jacobian density\n",
        "        prior = torch.sum(z**2, dim=1)\n",
        "        neg_log = 0.5 * prior - log_jac_det\n",
        "        \n",
        "        # calculate loss\n",
        "        return torch.mean(neg_log)\n",
        "\n",
        "    # TODO: Measure training time!\n",
        "    metrics = { 'train_loss': [], 'eval_loss': [] }\n",
        "    for epoch in range(epochs):\n",
        "        ## define logger\n",
        "        #pbar = tqdm(\n",
        "        #    desc=f'Epoch {epoch+1}/{epochs}',\n",
        "        #    total=len(train_loader),\n",
        "        #    position=0,\n",
        "        #    leave=True)\n",
        "        \n",
        "        # start training\n",
        "        flow.train()\n",
        "        train_loss = []\n",
        "        for i, (x, y) in enumerate(train_loader):\n",
        "            # prepare inputs\n",
        "            x, y = prepare_inputs(x, y)\n",
        "            \n",
        "            # calculate loss\n",
        "            loss = flow_loss(x, y)\n",
        "            train_loss.append(loss.cpu().detach())\n",
        "\n",
        "            # optimization step\n",
        "            flow_optim.zero_grad()\n",
        "            loss.backward()\n",
        "            flow_optim.step()\n",
        "\n",
        "            ## update bar\n",
        "            #pbar.update(1)\n",
        "            #pbar.set_description(f'Epoch: {epoch+1}/{epochs}, Loss: {loss.cpu()}')\n",
        "        \n",
        "        # store and print training loss\n",
        "        metrics['train_loss'].append(np.mean(np.array(train_loss)))\n",
        "        print(f'Epoch: {epoch+1}/{epochs}, Training Loss: {metrics[\"train_loss\"][-1]}')\n",
        "\n",
        "        # start evaluation\n",
        "        flow.eval()\n",
        "        with torch.no_grad():\n",
        "            losses = []\n",
        "            for (x, y) in test_loader:\n",
        "                # prepare inputs\n",
        "                x, y = prepare_inputs(x, y)\n",
        "\n",
        "                # calculate loss\n",
        "                loss = flow_loss(x, y)\n",
        "\n",
        "                # save loss\n",
        "                losses.append(loss.cpu().detach())\n",
        "            \n",
        "            # calc mean validation loss\n",
        "            loss = np.mean(np.array(losses))\n",
        "\n",
        "            # store and print validation loss\n",
        "            metrics['eval_loss'].append(loss)\n",
        "            print(f'Epoch: {epoch+1}/{epochs}, Val Loss: {metrics[\"eval_loss\"][-1]}')\n",
        "    return flow, flow_optim, metrics\n",
        "\n",
        "set_seed(9999)\n",
        "train_loader, test_loader = prepare_dataset()\n",
        "\n",
        "# define model\n",
        "print('Preparing generative flow... \\n\\n')\n",
        "flow = build_flow()\n",
        "flow = flow.cuda()\n",
        "\n",
        "# train the model\n",
        "flow, flow_optim, flow_metrics = train_flow(flow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfJLMkMbOtgT"
      },
      "source": [
        "Test generation capabilities of flow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PncaPuV8iXXn"
      },
      "source": [
        "# temp for sampling\n",
        "temp = 0.3\n",
        "\n",
        "# sample images\n",
        "with torch.no_grad():\n",
        "    cond = torch.randint(low=0, high=10, size=(256,))\n",
        "    cond = F.one_hot(cond, num_classes=10)\n",
        "    cond = cond.cuda()\n",
        "\n",
        "    z = temp * torch.cuda.FloatTensor(256, 1*28*28).normal_()\n",
        "    images, _ = flow(z, cond, rev=True)\n",
        "    images = images.view(-1, 28, 28)\n",
        "\n",
        "# take images to cpu for viz\n",
        "cond = cond.cpu()    \n",
        "images = images.cpu()\n",
        "\n",
        "# clamp images\n",
        "if True:\n",
        "    images = torch.clamp(images, 0., 1.)\n",
        "\n",
        "f, axs = plt.subplots(4, 4, figsize=(20,20))\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        index = i*4+j\n",
        "        im = axs[i][j].imshow(images[index], cmap='gray')\n",
        "        axs[i][j].set_title(f'Condition: {np.argmax(cond[index])}', fontsize=20)\n",
        "        f.colorbar(im, ax=axs[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpUaqZiibzoi"
      },
      "source": [
        "Save the model with optimizer and plot training and eval curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyM776IKbyQH"
      },
      "source": [
        "def save_model(model, optim, metrics, path=None):\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optim.state_dict(),\n",
        "        'metrics': metrics,\n",
        "    }, path)\n",
        "\n",
        "def plot_flow(metrics):\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.plot(metrics['train_loss'], label='Training', linewidth=3)\n",
        "    plt.plot(metrics['eval_loss'], label='Test', linewidth=3)\n",
        "    plt.title('Flow', fontsize=25)\n",
        "    plt.xlabel('Epochs', fontsize=25)\n",
        "    plt.ylabel('NLL', fontsize=25)\n",
        "    plt.xticks(fontsize=20)\n",
        "    plt.yticks(fontsize=20)\n",
        "    plt.legend(fontsize=20)\n",
        "\n",
        "# save the model\n",
        "save_model(flow, flow_optim, flow_metrics, path='flow.model')\n",
        "\n",
        "# plot training curve\n",
        "plot_flow(flow_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb0PUh_uxMiB"
      },
      "source": [
        "### Convolutional Classifiers\n",
        "\n",
        "First write an abstract training function for different settings we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60b3Byk7K2st"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "def train_conv(conv, preprocess_fn):\n",
        "    # define hyperparams\n",
        "    ### optimizer\n",
        "    lr = 0.01\n",
        "    betas = (0.9, 0.999)\n",
        "    eps = 1e-8\n",
        "    weight_decay = 1e-4 #1e-5\n",
        "\n",
        "    ### training\n",
        "    epochs = 20\n",
        "\n",
        "    # define optimizer & loss\n",
        "    conv_params = list(filter(lambda p: p.requires_grad, conv.parameters()))\n",
        "    conv_optim = Adam(\n",
        "        conv_params,\n",
        "        lr=lr,\n",
        "        betas=betas,\n",
        "        eps=eps,\n",
        "        weight_decay=weight_decay)\n",
        "    conv_sched = ExponentialLR(\n",
        "        conv_optim,\n",
        "        gamma=0.9\n",
        "    )\n",
        "    conv_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    # TODO: Measure training time!\n",
        "    metrics = { 'train_loss': [], 'train_acc': [], 'eval_loss': [], 'eval_acc': [] }\n",
        "    for epoch in range(epochs):\n",
        "        ## define logger\n",
        "        #pbar = tqdm(\n",
        "        #    desc=f'Epoch {epoch+1}/{epochs}',\n",
        "        #    total=len(train_loader),\n",
        "        #    position=0,\n",
        "        #    leave=True)\n",
        "        \n",
        "        # start training\n",
        "        train_loss = []\n",
        "        train_acc = []\n",
        "        for (x, y) in train_loader:\n",
        "            conv.train()\n",
        "\n",
        "            # preprocess data\n",
        "            x, y = preprocess_fn(x, y)\n",
        "\n",
        "            # feed-forward\n",
        "            preds = conv(x)\n",
        "            \n",
        "            # calculate loss & acc\n",
        "            loss = conv_loss(preds, y)\n",
        "            acc = torch.mean((torch.argmax(preds, axis=-1) == y) * 1.0)\n",
        "\n",
        "            # save loss & acc\n",
        "            train_loss.append(loss.cpu().detach())\n",
        "            train_acc.append(acc.cpu().detach())\n",
        "\n",
        "            # optimization step\n",
        "            conv_optim.zero_grad()\n",
        "            loss.backward()\n",
        "            conv_optim.step()\n",
        "\n",
        "            ## update bar\n",
        "            #pbar.update(1)\n",
        "            #pbar.set_description(f'Epoch: {epoch+1}/{epochs}, Loss: {loss.cpu()}')\n",
        "        \n",
        "        conv_sched.step()\n",
        "\n",
        "        # store and print training loss\n",
        "        metrics['train_loss'].append(np.mean(np.array(train_loss)))\n",
        "        metrics['train_acc'].append(np.mean(np.array(train_acc)))\n",
        "        print(f'Epoch: {epoch+1}/{epochs}, Training Loss: {metrics[\"train_loss\"][-1]}, Training Acc: {metrics[\"train_acc\"][-1]}')\n",
        "\n",
        "        # start evaluation\n",
        "        conv.eval()\n",
        "        with torch.no_grad():\n",
        "            losses = []\n",
        "            accs = []\n",
        "            for (x, y) in test_loader:\n",
        "                # put data on cuda (always test on real test set)\n",
        "                x, y = x.cuda(), y.cuda()\n",
        "\n",
        "                # feed-forward\n",
        "                preds = conv(x)\n",
        "\n",
        "                # calculate loss & acc\n",
        "                loss = conv_loss(preds, y)\n",
        "                acc = torch.mean((torch.argmax(preds, axis=-1) == y) * 1.0)\n",
        "\n",
        "                # save loss & acc\n",
        "                losses.append(loss.cpu().detach())\n",
        "                accs.append(acc.cpu().detach())\n",
        "            \n",
        "            # calc mean validation loss\n",
        "            loss = np.mean(np.array(losses))\n",
        "            acc = np.mean(np.array(accs))\n",
        "            \n",
        "            # store and print validation loss\n",
        "            metrics['eval_loss'].append(loss)\n",
        "            metrics['eval_acc'].append(acc)\n",
        "            print(f'Epoch: {epoch+1}/{epochs}, Val Loss: {metrics[\"eval_loss\"][-1]}, Val Acc: {metrics[\"eval_acc\"][-1]}')\n",
        "\n",
        "    return conv, conv_optim, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPdBzHwpN3sT"
      },
      "source": [
        "def plot_conv(metrics, title='Conv'):\n",
        "    # create a figure\n",
        "    fig, ax1 = plt.subplots(figsize=(12,6))\n",
        "\n",
        "    # loss\n",
        "    ax1.set_xlabel('Epochs', fontsize=25)\n",
        "    ax1.set_ylabel('Loss', fontsize=25)\n",
        "    ax1.plot(metrics['train_loss'], label='Training Loss', linewidth=3)\n",
        "    ax1.plot(metrics['eval_loss'], label='Test Loss', linestyle='dashed', linewidth=3)\n",
        "    ax1.tick_params(axis='y', labelsize=20)\n",
        "    ax1.tick_params(axis='x', labelsize=20)\n",
        "    handles1, labels1 = ax1.get_legend_handles_labels()\n",
        "\n",
        "    # accuracy\n",
        "    ax2 = ax1.twinx() \n",
        "    ax2.set_ylabel('Accuracy', fontsize=25)\n",
        "    ax2.plot(metrics['train_acc'], label='Train Acc', color='g', linewidth=3)\n",
        "    ax2.plot(metrics['eval_acc'], label='Test Acc', color='r', linestyle='dashed', linewidth=3)\n",
        "    ax2.tick_params(axis='y', labelsize=20)\n",
        "    handles2, labels2 = ax2.get_legend_handles_labels()\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.legend(handles1+handles2, labels1+labels2, fontsize=20, loc='center right')\n",
        "    plt.title(title, fontsize=25)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXniZZqSLZlu"
      },
      "source": [
        "#### On Standard Data\n",
        "\n",
        "Now, let's train a convolutional network directly on standard data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjKxJS0LCwrD"
      },
      "source": [
        "# define model\n",
        "print('Preparing convolutional classifier... \\n\\n')\n",
        "conv_standard = build_conv()\n",
        "conv_standard = conv_standard.cuda()\n",
        "\n",
        "set_seed(9999)\n",
        "train_loader, test_loader = prepare_dataset()\n",
        "\n",
        "# print model\n",
        "summary(conv_standard, input_size=(1, 28, 28))\n",
        "\n",
        "preprocess_standard = lambda x, y: (x.cuda(), y.cuda())\n",
        "conv_standard, conv_standard_optim, conv_standard_metrics = train_conv(conv_standard, preprocess_standard)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKcLgf9niw7E"
      },
      "source": [
        "# save the model\n",
        "save_model(conv_standard, conv_standard_optim, conv_standard_metrics, path='conv_standard.model')\n",
        "\n",
        "# plot training curve\n",
        "plot_conv(conv_standard_metrics, title='Standard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BPHQuVjCxmg"
      },
      "source": [
        "#### On Flow Generated Data\n",
        "\n",
        "Now, utilize normalizing flow as a data source and train a new classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUw6HBGpQSp7"
      },
      "source": [
        "# define model\n",
        "print('Preparing 2nd convolutional classifier... \\n\\n')\n",
        "conv_flow = build_conv()\n",
        "conv_flow = conv_flow.cuda()\n",
        "\n",
        "# print model\n",
        "summary(conv_flow, input_size=(1, 28, 28))\n",
        "\n",
        "# use flow-generated dataset instead of standard train set\n",
        "def preprocess_flow(x, y, temp=0.75, clamp=True):\n",
        "    # prepare y\n",
        "    y = torch.randint(low=0, high=10, size=(256,))\n",
        "    y = y.cuda()\n",
        "\n",
        "    # prepare z and cond\n",
        "    cond = F.one_hot(y, num_classes=10)\n",
        "    z = temp * torch.cuda.FloatTensor(256, 1*28*28).normal_()\n",
        "\n",
        "    # generate images\n",
        "    with torch.no_grad():\n",
        "        images, _ = flow(z, cond, rev=True)\n",
        "\n",
        "    # clamp images\n",
        "    if clamp:\n",
        "        images = torch.clamp(images, 0., 1.)\n",
        "\n",
        "    images = images.detach()\n",
        "    images = images.view(-1, 1, 28, 28)\n",
        "    return images, y\n",
        "\n",
        "# train model on flow-generated dataset\n",
        "conv_flow, conv_flow_optim, conv_flow_metrics = train_conv(conv_flow, preprocess_flow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIYW1HkHi51b"
      },
      "source": [
        "# save the model\n",
        "save_model(conv_flow, conv_flow_optim, conv_flow_metrics, path='conv_flow.model')\n",
        "\n",
        "# plot training curve\n",
        "plot_conv(conv_flow_metrics, title='Synthetic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_byZjb_M0Pt"
      },
      "source": [
        "#### On Away Perturbed Flow-embeddings \n",
        "\n",
        "Now, use perturbed representations in Flow to generate images for a new classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUU_OmQIM7Qo"
      },
      "source": [
        "# define model\n",
        "print('Preparing 3nd convolutional classifier... \\n\\n')\n",
        "conv_pert = build_conv()\n",
        "conv_pert = conv_pert.cuda()\n",
        "\n",
        "# print model\n",
        "summary(conv_pert, input_size=(1, 28, 28))\n",
        "\n",
        "# use away perturbed embeddings of flow\n",
        "def preprocess_pert(x, y, pert=0.1):\n",
        "    # preprocess for flow\n",
        "    x = x.view(-1, 1*28*28)\n",
        "    y_hot = F.one_hot(y, num_classes=10)\n",
        "\n",
        "    # put data on cuda\n",
        "    x, y_hot = x.cuda(), y_hot.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # embed images\n",
        "        z, _ = flow(x, y_hot)\n",
        "\n",
        "        # perturb images\n",
        "        z = z + (1. + pert)\n",
        "\n",
        "        # generate new images with flow\n",
        "        images, _ = flow(z, y_hot, rev=True)\n",
        "\n",
        "    images = images.detach()\n",
        "    images = images.view(-1, 1, 28, 28)\n",
        "    return images, y.cuda()\n",
        "\n",
        "# train model on flow-perturbed samples\n",
        "conv_pert, conv_pert_optim, conv_pert_metrics = train_conv(conv_pert, preprocess_pert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2O7yFvPjA6m"
      },
      "source": [
        "# save the model\n",
        "save_model(conv_pert, conv_pert_optim, conv_pert_metrics, path='conv_pert.model')\n",
        "\n",
        "# plot training curve\n",
        "plot_conv(conv_pert_metrics, title='Away-LA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl4jKpKHYt7j"
      },
      "source": [
        "#### On Randomized Flow-embeddings\n",
        "\n",
        "Now, use randomized representations in Flow to generate images for a new classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M0vJL8GYRPY"
      },
      "source": [
        "# define model\n",
        "print('Preparing 4th convolutional classifier... \\n\\n')\n",
        "conv_rand = build_conv()\n",
        "conv_rand = conv_rand.cuda()\n",
        "\n",
        "set_seed(9999)\n",
        "train_loader, test_loader = prepare_dataset()\n",
        "\n",
        "# print model\n",
        "summary(conv_rand, input_size=(1, 28, 28))\n",
        "\n",
        "# use randomized embeddings of flow\n",
        "def preprocess_rand(x, y, pert=0.15):\n",
        "    # preprocess for flow\n",
        "    x = x.view(-1, 1*28*28)\n",
        "    y_hot = F.one_hot(y, num_classes=10)\n",
        "\n",
        "    # put data on cuda\n",
        "    x, y_hot = x.cuda(), y_hot.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # embed images\n",
        "        z, _ = flow(x, y_hot)\n",
        "\n",
        "        # perturb images\n",
        "        z = z + pert * torch.cuda.FloatTensor(x.shape).normal_()\n",
        "\n",
        "        # generate new images with flow\n",
        "        images, _ = flow(z, y_hot, rev=True)\n",
        "\n",
        "    images = images.detach()\n",
        "    images = images.view(-1, 1, 28, 28)\n",
        "    return images, y.cuda()\n",
        "\n",
        "# train model on flow-perturbed samples\n",
        "conv_rand, conv_rand_optim, conv_rand_metrics = train_conv(conv_rand, preprocess_rand)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y3dD90VjIVP"
      },
      "source": [
        "# save the model\n",
        "save_model(conv_rand, conv_rand_optim, conv_rand_metrics, path='conv_rand.model')\n",
        "\n",
        "# plot training curve\n",
        "plot_conv(conv_rand_metrics, title='Randomized-LA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sghH3fE-BNZ"
      },
      "source": [
        "#### On Adversarial Flow-embeddings\n",
        "\n",
        "Now, use adversarial representations in Flow to generate images for a new classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PdW6AkZ-IiR"
      },
      "source": [
        "# define model\n",
        "print('Preparing 5th convolutional classifier... \\n\\n')\n",
        "conv_adv = build_conv()\n",
        "conv_adv = conv_adv.cuda()\n",
        "\n",
        "set_seed(9999)\n",
        "train_loader, test_loader = prepare_dataset()\n",
        "\n",
        "# print model\n",
        "summary(conv_adv, input_size=(1, 28, 28))\n",
        "\n",
        "# use adversarial embeddings of flow\n",
        "conv_loss = nn.CrossEntropyLoss()\n",
        "conv_adv_pert = conv_adv\n",
        "def preprocess_adv(x, y, pert=0.05, alpha=0.01, steps=10):\n",
        "    flow.eval()\n",
        "    conv_adv_pert.eval()\n",
        "\n",
        "    # preprocess for flow\n",
        "    x = x.view(-1, 1*28*28)\n",
        "    y_hot = F.one_hot(y, num_classes=10)\n",
        "\n",
        "    # put data on cuda\n",
        "    x, y, y_hot = x.cuda(), y.cuda(), y_hot.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # embed images\n",
        "        z, _ = flow(x, y_hot)\n",
        "\n",
        "    dz = torch.zeros_like(z).to(z.device)\n",
        "    dz.requires_grad = True\n",
        "    for i in range(steps):\n",
        "        with torch.enable_grad():\n",
        "            # clean gradients\n",
        "            flow.zero_grad()\n",
        "            conv_adv_pert.zero_grad()\n",
        "\n",
        "            #  feed-forward\n",
        "            out, _ = flow(z + dz, y_hot, rev=True)\n",
        "            out = out.view(-1, 1, 28, 28)\n",
        "\n",
        "            preds = conv_adv_pert(out)\n",
        "            loss = conv_loss(preds, y)\n",
        "\n",
        "            # get gradient\n",
        "            grad = torch.autograd.grad(\n",
        "                loss, dz, retain_graph=False, create_graph=False\n",
        "            )[0]\n",
        "\n",
        "            dz = dz + torch.sign(grad) * alpha\n",
        "            dz = torch.clamp(dz, -pert, +pert)\n",
        "\n",
        "    # perturb images\n",
        "    z = z + dz\n",
        "    # generate new images with flow\n",
        "    images, _ = flow(z, y_hot, rev=True)\n",
        "\n",
        "    images = images.detach()\n",
        "    images = images.view(-1, 1, 28, 28)\n",
        "    return images, y.cuda()\n",
        "\n",
        "# train model on flow-generated samples\n",
        "conv_adv, conv_adv_optim, conv_adv_metrics = train_conv(conv_adv, preprocess_adv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z9pjc8y-TkX"
      },
      "source": [
        "# save the model\n",
        "save_model(conv_adv, conv_adv_optim, conv_adv_metrics, path='conv_adv.model')\n",
        "\n",
        "# plot training curve\n",
        "plot_conv(conv_adv_metrics, title='Adversarial-LA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3W-EItVEq_u"
      },
      "source": [
        "#### On Image-Space Adversarial (PGD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GluKl9MvEu5b"
      },
      "source": [
        "# define model\n",
        "print('Preparing 6th convolutional classifier... \\n\\n')\n",
        "conv_pgd = build_conv()\n",
        "conv_pgd = conv_pgd.cuda()\n",
        "\n",
        "set_seed(9999)\n",
        "train_loader, test_loader = prepare_dataset()\n",
        "\n",
        "# print model\n",
        "summary(conv_pgd, input_size=(1, 28, 28))\n",
        "\n",
        "# use adversarial embeddings of flow\n",
        "conv_loss = nn.CrossEntropyLoss()\n",
        "conv_pgd_pert = conv_pgd\n",
        "def preprocess_pgd(x, y, pert=0.3, alpha=0.01, steps=40):\n",
        "    conv_pgd_pert.eval()\n",
        "\n",
        "    # put data on cuda\n",
        "    x, y = x.cuda(), y.cuda()\n",
        "\n",
        "    dx = torch.zeros_like(x).to(x.device)\n",
        "    dx.requires_grad = True\n",
        "    for i in range(steps):\n",
        "        with torch.enable_grad():\n",
        "            # clean gradients\n",
        "            conv_pgd_pert.zero_grad()\n",
        "\n",
        "            preds = conv_pgd_pert(x + dx)\n",
        "            loss = conv_loss(preds, y)\n",
        "\n",
        "            # get gradient\n",
        "            grad = torch.autograd.grad(\n",
        "                loss, dx, retain_graph=False, create_graph=False\n",
        "            )[0]\n",
        "\n",
        "            dx = dx + torch.sign(grad) * alpha\n",
        "            dx = torch.clamp(dx, -pert, +pert)\n",
        "\n",
        "    # perturb images\n",
        "    x = x + dx\n",
        "\n",
        "    return x, y.cuda()\n",
        "\n",
        "# train model on flow-generated samples\n",
        "conv_pgd, conv_pgd_optim, conv_pgd_metrics = train_conv(conv_pgd, preprocess_pgd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDSHjCkrE77d"
      },
      "source": [
        "# save the model\n",
        "save_model(conv_pgd, conv_pgd_optim, conv_pgd_metrics, path='conv_pgd.model')\n",
        "\n",
        "# plot training curve\n",
        "plot_conv(conv_pgd_metrics, title='PGD')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ74KNiQFS3t"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Reload models for evaluation purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpCOdh5bCdTq"
      },
      "source": [
        "# load state dictionaries\n",
        "flow_dict = torch.load('flow.model')\n",
        "conv_standard_dict = torch.load('conv_standard.model')\n",
        "conv_flow_dict = torch.load('conv_flow.model')\n",
        "conv_pert_dict = torch.load('conv_pert.model')\n",
        "conv_rand_dict = torch.load('conv_rand.model')\n",
        "conv_adv_dict = torch.load('conv_adv.model')\n",
        "\n",
        "# load models\n",
        "flow = build_flow()\n",
        "flow = flow.cuda()\n",
        "flow.load_state_dict(flow_dict['model_state_dict'])\n",
        "\n",
        "conv_standard = build_conv()\n",
        "conv_standard = conv_standard.cuda()\n",
        "conv_standard.load_state_dict(conv_standard_dict['model_state_dict'])\n",
        "\n",
        "conv_flow = build_conv()\n",
        "conv_flow = conv_flow.cuda()\n",
        "conv_flow.load_state_dict(conv_flow_dict['model_state_dict'])\n",
        "\n",
        "conv_pert = build_conv()\n",
        "conv_pert = conv_pert.cuda()\n",
        "conv_pert.load_state_dict(conv_pert_dict['model_state_dict'])\n",
        "\n",
        "conv_rand = build_conv()\n",
        "conv_rand = conv_rand.cuda()\n",
        "conv_rand.load_state_dict(conv_rand_dict['model_state_dict'])\n",
        "\n",
        "conv_adv = build_conv()\n",
        "conv_adv = conv_adv.cuda()\n",
        "conv_adv.load_state_dict(conv_adv_dict['model_state_dict'])\n",
        "\n",
        "conv_pgd = build_conv()\n",
        "conv_pgd = conv_pgd.cuda()\n",
        "conv_pgd.load_state_dict(conv_pgd_dict['model_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byx_hLVxH-ej"
      },
      "source": [
        "Now compare five classifier models in terms of accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YojQjIRa-lmo"
      },
      "source": [
        "set_seed(9999)\n",
        "_, test_loader = prepare_dataset()\n",
        "\n",
        "def calc_acc(model, preprocess_fn):\n",
        "    with torch.no_grad():\n",
        "        accs = []\n",
        "        for (x, y) in test_loader:\n",
        "            # put data on cuda\n",
        "            x, y = preprocess_fn(x, y)\n",
        "\n",
        "            # feed-forward\n",
        "            preds = model(x)\n",
        "            preds = torch.argmax(preds, axis=1)\n",
        "\n",
        "            # calculate accuracy\n",
        "            acc = (preds == y) * 1.\n",
        "\n",
        "            # save loss\n",
        "            accs.append(torch.mean(acc))\n",
        "        \n",
        "        # calc mean validation loss\n",
        "        acc = torch.mean(torch.Tensor(accs))\n",
        "        print(f'Test Acc: {acc.cpu()}')\n",
        "\n",
        "preprocess = preprocess_adv\n",
        "\n",
        "conv_adv_pert = conv_standard\n",
        "print('Running evalution on standard conv...')\n",
        "calc_acc(conv_standard, preprocess)\n",
        "print()\n",
        "\n",
        "conv_adv_pert = conv_flow\n",
        "print('Running evalution on synthetic conv...')\n",
        "calc_acc(conv_flow, preprocess)\n",
        "print()\n",
        "\n",
        "conv_adv_pert = conv_pert\n",
        "print('Running evalution on perturbed (away) Flow-embeddings conv...')\n",
        "calc_acc(conv_pert, preprocess)\n",
        "print()\n",
        "\n",
        "conv_adv_pert = conv_rand\n",
        "print('Running evalution on randomized Flow-embeddings conv...')\n",
        "calc_acc(conv_rand, preprocess)\n",
        "print()\n",
        "\n",
        "conv_adv_pert = conv_adv\n",
        "print('Running evalution on adversarial Flow-embeddings conv...')\n",
        "calc_acc(conv_adv, preprocess)\n",
        "print()\n",
        "\n",
        "conv_adv_pert = conv_pgd\n",
        "print('Running evalution on PGD conv...')\n",
        "calc_acc(conv_pgd, preprocess)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9KPVu5MH6iD"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JntNERcmXE_"
      },
      "source": [
        "set_seed(9999)\n",
        "_, test_loader = prepare_dataset()\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images = images[:9, 0, ...]\n",
        "    labels = labels[:9]\n",
        "    break\n",
        "\n",
        "def viz_inputs(preprocess_fn, images, labels):\n",
        "    images, labels = preprocess_fn(images, labels)\n",
        "    images, labels = images.cpu(), labels.cpu()\n",
        "\n",
        "    if len(images.shape) == 4:\n",
        "        images = images[:, 0, ...]\n",
        "\n",
        "    f, axs = plt.subplots(3, 3, figsize=(12,12))\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            index = i*3+j\n",
        "            im = axs[i][j].imshow(images[index], cmap='gray')\n",
        "            axs[i][j].set_title(f'Label: {labels[index]}', fontsize=25)\n",
        "            axs[i][j].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
        "            #f.colorbar(im, ax=axs[i][j])\n",
        "    return images\n",
        "\n",
        "def preprocess(images, labels):\n",
        "    return preprocess_adv(images, labels, pert=0.1, alpha=0.03, steps=10)\n",
        "\n",
        "_ = viz_inputs(preprocess, images, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAsVVwUR892Z"
      },
      "source": [
        "images_diff = np.abs(images_perturbed - images_clean)\n",
        "\n",
        "f, axs = plt.subplots(3, 3, figsize=(12,12))\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        index = i*3+j\n",
        "        im = axs[i][j].imshow(images_diff[index], cmap='BuPu')\n",
        "        axs[i][j].set_title(f'Label: {labels[index]}', fontsize=25)\n",
        "        axs[i][j].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
        "        #f.colorbar(im, ax=axs[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmvNtD3V9b_k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}